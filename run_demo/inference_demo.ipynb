{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Load Module =========\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "from scipy.signal import find_peaks\n",
    "import sys\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "\n",
    "model_path = 'data_model/model_checkpoint.pth' # MSFSegNet-31+51-32-tanh-01111-bs8-lr1.0e-04-BCE-SGD-S2\n",
    "sample_list = ['/data/wht/seismic/RCP/yz/gth/gth_Line1650_Cdp1382.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Load Sample ========\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== process data ========\n",
    "from models.cascade_method.seg_nets import MSFSegNet\n",
    "from models.cascade_method.get_curve import split_group, interp_curves\n",
    "from models.cascade_method.gauss_reg import posterior_regression\n",
    "from models.cascade_method.clu_curves import clustering_main\n",
    "\n",
    "import torch\n",
    "\n",
    "def predict_single(gth, model_path, agc_list=[11, 15], m=32, device=0):\n",
    "    pred_hyper_dict={'win_k': 3, 'bw_data': 5, 'bw_para': 50, 'valid_range': 50, 'min_len': 5, 'clu_eps': 4}\n",
    "    \n",
    "    # prepare input\n",
    "    h, w = gth.shape\n",
    "    h_new = (h//m+1)*m if h%m > 0 else h\n",
    "    w_new = (w//m+1)*m if w%m > 0 else w\n",
    "    gth_pad = np.zeros((h_new, w_new), dtype=np.float32)\n",
    "    gth_pad[:h, :w] = gth\n",
    "    gth_peak_map = np.zeros((h_new, w_new), dtype=np.float32)\n",
    "    peak_map = np.zeros_like(gth)\n",
    "    for j, trace in enumerate(gth.T):\n",
    "        peaks, _ = find_peaks(trace, height=0)\n",
    "        peak_map[peaks, j] = 1\n",
    "            \n",
    "    gth_peak_map[:h, :w] = peak_map\n",
    "    gth_feat = np.concatenate([gth_pad[np.newaxis, ...], gth_peak_map[np.newaxis, ...]], axis=0)\n",
    "    gth_feat_torch = torch.from_numpy(gth_feat).unsqueeze(0).cuda(device)\n",
    "    \n",
    "    # load model\n",
    "    picker = MSFSegNet(agc_list=[15,31], CBAM_reduction=32, basic_act='tanh', dcn_use=0, cbam_use=1, add_peak=1, add_bp=1, device=device)\n",
    "    picker.cuda(device)\n",
    "    model_file = torch.load(model_path, map_location='cuda:%s'%device)\n",
    "    picker.load_state_dict(model_file['weights'])\n",
    "    picker.change_agc(agc_list, device)\n",
    "    \n",
    "    # * stage 1\n",
    "    # inference of MSFSegNet\n",
    "    seg_map, mult_feats = picker(gth_feat_torch)\n",
    "    seg_map = seg_map.cpu().detach().numpy()[:h, :w]\n",
    "    mult_feats = mult_feats.squeeze().cpu().detach().numpy()[:, :h, :w]\n",
    "    \n",
    "    # post process\n",
    "    # * stage 2\n",
    "    curve_auto = split_group(seg_map)\n",
    "    curve_auto_interp = interp_curves(curve_auto)\n",
    "    curve_auto_interp_cp = curve_auto_interp.copy()\n",
    "    for name in curve_auto_interp_cp:\n",
    "        if len(curve_auto_interp_cp[name]) < pred_hyper_dict['win_k']:\n",
    "            curve_auto_interp.pop(name)\n",
    "    # * stage 3\n",
    "    infer_opt = posterior_regression(win_k=pred_hyper_dict['win_k'], bw_data=pred_hyper_dict['bw_data'], bw_para=pred_hyper_dict['bw_para'])\n",
    "    field_auto, slope_dict = infer_opt.est_prior(curve_auto_interp, gth.shape, valid_range=pred_hyper_dict['valid_range'])\n",
    "    curve_concat, labels = clustering_main(curve_auto_interp, slope_dict, eps=pred_hyper_dict['clu_eps'])\n",
    "    # * stage 4\n",
    "    curve_dict_smooth = infer_opt.infer_posterior(curve_concat, field_auto)\n",
    "    curve_dict_smooth_cp = curve_dict_smooth.copy()\n",
    "    for name in curve_dict_smooth_cp:\n",
    "        if len(curve_dict_smooth[name]) < pred_hyper_dict['min_len']:\n",
    "            curve_dict_smooth.pop(name)\n",
    "\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "predict_single(np.load(sample_list[0]).T, model_path, device=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
